{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import docx2txt\n",
    "import re\n",
    "import json\n",
    "from os import listdir\n",
    "from collections import Counter\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in word file\n",
    "play_text = docx2txt.process('Word_Docs/133.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_characters(play_text):\n",
    "    play_text = play_text.replace('\\n\\n', '\\n')\n",
    "    characters_summary = {}\n",
    "    characters = play_text[play_text.find('LES ACTEURS')+len('LES ACTEURS'):\n",
    "                                   play_text.find('ACTE 1')]\n",
    "    noise = ['', ' ', '\\xa0', '-', '–', '/']\n",
    "    dramatic_characters = [character.strip() for character in characters.split('\\n') if character not in noise]\n",
    "    for character in dramatic_characters:\n",
    "        collective_number = re.findall('\\d', character)\n",
    "        if len(collective_number) == 0:\n",
    "            characters_summary[character] = {'collective_number': None}\n",
    "        else:\n",
    "            number = collective_number[0]\n",
    "            character = character.replace(number, '').strip()\n",
    "            characters_summary[character] = {'collective_number': int(number)}\n",
    "    \n",
    "    return characters_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speach_analysis(scene_characters, characters_dict):\n",
    "    speach_dict = {'number_speaking_characters': 0, 'number_non_speaking_characters':0}\n",
    "    characters = [key for key in scene_characters.keys() if key not in ['num_speakers']]\n",
    "    for character in  characters:\n",
    "        collective_num = characters_dict[character]['collective_number']\n",
    "        if scene_characters[character] == 'speaking' and collective_num == None:\n",
    "            speach_dict['number_speaking_characters'] += 1\n",
    "        elif scene_characters[character] == 'speaking' and collective_num != None:\n",
    "            speach_dict['number_speaking_characters'] += characters_dict[character]['collective_number']\n",
    "        elif scene_characters[character] == 'non_speaking':\n",
    "            speach_dict['number_non_speaking_characters'] += 1\n",
    "    speach_dict['percentage_non_speaking'] = round((speach_dict['number_non_speaking_characters'] / \n",
    "                                                    len(characters)) * 100, 3)              \n",
    "    return speach_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def character_parsing(names, characters):\n",
    "    scene_characters = {}\n",
    "    for name in names:                 \n",
    "        symbols = ['-', '–', '*', '/']\n",
    "        for symbol in symbols:\n",
    "            name = name.replace(symbol, '')\n",
    "        if name.lower().count('молчит')> 0 :\n",
    "            name = name.lower().replace('молчит', '').upper()\n",
    "            speaking_status = 'non_speaking'\n",
    "        else:\n",
    "            speaking_status = 'speaking'\n",
    "        name = name.strip()\n",
    "        if name.isdigit() == False and name != '':\n",
    "            scene_characters[name] = speaking_status\n",
    "   \n",
    "    scene_characters['num_speakers'] = speach_analysis(scene_characters, characters)['number_speaking_characters']\n",
    "    scene_characters['perc_non_speakers'] = speach_analysis(scene_characters, characters)['percentage_non_speaking']\n",
    "    \n",
    "    return scene_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_scenes(scenes,  characters):\n",
    "    scene_summary = {}\n",
    "    noise = ['', ' ', '\\xa0', '-', '–', '/']\n",
    "    extra_scene_number = 1\n",
    "    regular_num = 1\n",
    "    for scene in scenes:\n",
    "        names = [name.strip() for name in scene[1:].split('\\n') if name not in noise]\n",
    "        if scene[0].isdigit() and scene[1:5].count('*') == 0:\n",
    "            scene_name = str(regular_num) +'_regular'\n",
    "            regular_num += 1\n",
    "            extra_scene_number = 1\n",
    "        elif scene[0].isdigit() and scene[1:5].count('*') > 0:\n",
    "            scene_name =  str(regular_num) + '_no_change'\n",
    "            regular_num += 1\n",
    "            extra_scene_number = 1\n",
    "        else: \n",
    "            scene_name =  str(regular_num - 1)+'.' + str(extra_scene_number) +'_extra'\n",
    "            extra_scene_number += 1\n",
    "        scene_summary[scene_name] = character_parsing(names,  characters)\n",
    "    \n",
    "    return scene_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_play_summary(play_data, play_text):\n",
    "    play_data['characters'] = parse_characters(play_text)\n",
    "    play_summary = {}\n",
    "    noise = ['', ' ', '\\xa0', '-', '–', '/']\n",
    "    acts = [act for act in play_text[play_text.find('ACTE 1'):].split('ACTE') if act not in noise]\n",
    "    for act_num, act in enumerate(acts, 1):\n",
    "        scenes =   [scene.strip() for scene in act.split('SCENE')][1:]\n",
    "        play_summary['act_'+ str(act_num)] = parse_scenes(scenes,  play_data['characters'])\n",
    "    play_data['play_summary'] = play_summary\n",
    "    \n",
    "    return play_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_number_scenes(scene_summary):\n",
    "    \"\"\"\n",
    "    The function calcualtes the number of scenes per text and per Iarkho (i.e., as marked by actual dramatic character\n",
    "    entrances and exits).\n",
    "    Params:\n",
    "        scene_summary - a dictionary output of the parse_play function.\n",
    "    Returns:\n",
    "        total_number_scenes_per_text - number of scenes as they are printed\n",
    "        total_number_scenes_iarkho - number of scnes per Iarkho, which he calls mobility coefficient (MC)\n",
    "    \"\"\"\n",
    "    total_number_scenes_per_text = 0\n",
    "    total_number_scenes_iarkho = 0\n",
    "    for key in scene_summary.keys():\n",
    "        # get the number of scenes as it is printed in the text\n",
    "        total_number_scenes_per_text+=len([scene for scene in scene_summary[key].keys() if scene.count('extra')==0])\n",
    "        # count scenes as marked by actual entrances and exits                                  \n",
    "        total_number_scenes_iarkho+=len([scene for scene in scene_summary[key].keys() if scene.count('no_change')==0])\n",
    "    \n",
    "    return total_number_scenes_per_text, total_number_scenes_iarkho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_speaking_no_change_case(previous_scene, no_change_scene):\n",
    "    speaking_set = set()\n",
    "    non_speaking_set = set()\n",
    "    for key in previous_scene.keys():\n",
    "        if previous_scene[key] =='speaking' or no_change_scene[key]=='speaking':\n",
    "            speaking_set.add(key)\n",
    "        if previous_scene[key] =='non_speaking' or no_change_scene[key]=='non_speaking':\n",
    "            non_speaking_set.add(key)\n",
    "    num_non_speaking = len(non_speaking_set.difference(speaking_set))\n",
    "    num_speaking = len(speaking_set)\n",
    "    perc_non_speaking = round((num_non_speaking / (num_non_speaking + num_speaking)) * 100, 3)\n",
    "    \n",
    "    return num_speaking, perc_non_speaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_no_change_scenes(play_summary):\n",
    "    which_to_exclude = []\n",
    "    speakers = []\n",
    "    perc_non_speakers = []\n",
    "    for act in play_summary.keys():\n",
    "        analysed_scenes = []\n",
    "        for scene in list(play_summary[act].keys()):\n",
    "            if scene.count('no_change') > 0:\n",
    "\n",
    "                num_speaking, perc_non_speaking = number_speaking_no_change_case(\n",
    "                                                  play_summary[act][analysed_scenes[-1]],\n",
    "                                                  play_summary[act][scene])\n",
    "                speakers.append(num_speaking)\n",
    "                perc_non_speakers.append(perc_non_speaking)\n",
    "                which_to_exclude.append((act, scene, analysed_scenes[-1]))\n",
    "            analysed_scenes.append(scene)\n",
    "    \n",
    "    return which_to_exclude, speakers, perc_non_speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_combined_scenes(play_dict, values_to_exclude):\n",
    "    \"\"\"\n",
    "    The function removes info about scenes that we have previously combined and calculated combined data\n",
    "    for in cases when there was no change in character cast.\n",
    "    Params:\n",
    "        play_dict - a dictionary with speakers for each scene.\n",
    "        values_to_exlude - a list of typles where the first value is the act and the other values are scenes.\n",
    "        \n",
    "    Returns:\n",
    "        play_dict - without exluded scenes.\n",
    "    \"\"\"\n",
    "    for value in values_to_exclude:\n",
    "        result = {key : val for key, val in play_dict[value[0]].items() \n",
    "                        if key not in value[1:]}\n",
    "        play_dict[value[0]] = result\n",
    "        \n",
    "    return play_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_play_summary(play_summary_copy):\n",
    "    values_to_exclude, speakers, perc_non_speakers = combine_no_change_scenes(play_summary_copy)\n",
    "    play_summary_updated = remove_combined_scenes(play_summary_copy, values_to_exclude)\n",
    "    for key in play_summary_updated.keys():\n",
    "        for scene in play_summary_updated[key]:\n",
    "            speakers.append((play_summary_updated[key][scene]['num_speakers']))\n",
    "            perc_non_speakers.append(round(play_summary_updated[key][scene]['perc_non_speakers'], 3))\n",
    "    \n",
    "    return speakers, perc_non_speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_distribution_iarkho(play_summary_copy):\n",
    "    \"\"\"\n",
    "    The function creates speech distrubution per Iarkho, i.e., the number of speaking characters by number of scenes.\n",
    "    Params:\n",
    "        play_summary - a dictionary output by parse_play function.\n",
    "    Returns:\n",
    "        speech_distribution - a list of tuples were the 0 element is the number of speaking characters\n",
    "                              and the 1 element is the number of scenes with such number of speaking characters.\n",
    "    \"\"\"\n",
    "    \n",
    "    speakers, perc_non_speakers = preprocess_play_summary(play_summary_copy)\n",
    "    counter = Counter\n",
    "    counted = counter(speakers)\n",
    "    speech_distribution = sorted(counted.items(), key=lambda pair: pair[0], reverse=False)\n",
    "    speech_types = percentage_of_each_speech_type(speech_distribution)\n",
    "    av_perc_non_speakers = round(np.mean((perc_non_speakers)), 3)\n",
    "    \n",
    "    return speech_distribution, speech_types, av_perc_non_speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma_iarkho(variants, weights):  \n",
    "    \"\"\" \n",
    "    The function allows calculating standard range following iarkho's procedure. \n",
    "    Parameters: \n",
    "        variants - a list with distinct variants in the ascending order, e.g. [1, 2, 3, 4, 5] \n",
    "        weights - a list of weights corresponding to these variants, e.g. [20, 32, 18, 9, 1] \n",
    "    Returns: \n",
    "        sigma - standard range per iarkho \n",
    "    \"\"\"  \n",
    "    weighted_mean_variants = np.average(variants, weights=weights)  \n",
    "    differences_squared = [(variant - weighted_mean_variants)**2 for variant in variants] \n",
    "    weighted_mean_difference = np.average(differences_squared, weights=weights)  \n",
    "    sigma = weighted_mean_difference**0.5  \n",
    "      \n",
    "    return sigma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_of_each_speech_type(speech_distribution):\n",
    "    \"\"\"\n",
    "    The function calculates the percentage of each speech type (monologue, duologue, non-duologue (meaning not two\n",
    "    speakers), and over-two speakers) of the total accross all speech types.\n",
    "    Params:\n",
    "        speech_distibution - number of scenes with a specified number of speakers.\n",
    "    Returns:\n",
    "        speech_types - a dictionary with percentages corresponding to each speech type.\n",
    "    \"\"\"\n",
    "    speech_types = {}\n",
    "    total_scenes = np.sum([speech_type[1] for speech_type in  speech_distribution])\n",
    "    speech_types['perc_monologue'] = np.round((np.sum([speech_type[1] for speech_type in  speech_distribution \n",
    "                                    if speech_type[0] ==1]) / total_scenes) *100, 2)\n",
    "    speech_types['perc_duologue'] = np.round((np.sum([speech_type[1] for speech_type in  speech_distribution \n",
    "                                    if speech_type[0] == 2])/ total_scenes) * 100, 2)\n",
    "    speech_types['perc_non_duologue'] = np.round((np.sum([speech_type[1] for speech_type in  speech_distribution \n",
    "                                        if speech_type[0] != 2])/ total_scenes) * 100, 2)\n",
    "    speech_types['perc_over_two_speakers'] = np.round((np.sum([speech_type[1] for speech_type in  speech_distribution \n",
    "                                             if speech_type[0] > 2])/ total_scenes) * 100, 2)\n",
    "    \n",
    "    return speech_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_present_characters(play_dictionary):\n",
    "    \"\"\"\n",
    "    The function calculates the number of characters present in the play. If a character is listed in cast, but doesn't\n",
    "    appear on stage, he/she doesn't count.\n",
    "    Params:\n",
    "        play_dictionary - a dictioanry with data for the play, which includes the characters present in each scene.\n",
    "    Returns:\n",
    "        total_number_present_characters - int.\n",
    "    \"\"\"\n",
    "    all_present_characters = set()\n",
    "    for key in play_dictionary['play_summary'].keys():\n",
    "        for scene in play_dictionary['play_summary'][key]:\n",
    "            for item in play_dictionary['play_summary'][key][scene].keys():\n",
    "                if item != 'num_speakers' and item != 'perc_non_speakers':\n",
    "                    all_present_characters.add(item)\n",
    "    total_number_present_characters = 0\n",
    "    if len(set(all_present_characters).difference(set(play_dictionary['characters']))) > 0:\n",
    "        print('Error. Incorrect character name present in a scene.')\n",
    "    appearing_on_stage = set(play_dictionary['characters']).intersection(all_present_characters)\n",
    "    for character in appearing_on_stage: \n",
    "        coll_number = play_dictionary['characters'][character]['collective_number']\n",
    "        # if there is a collective number for this character\n",
    "        if coll_number:\n",
    "            total_number_present_characters += int(coll_number)\n",
    "        else:\n",
    "            total_number_present_characters += 1\n",
    "\n",
    "    return total_number_present_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_speakers_features(play_data, metadata_dict):\n",
    "    \"\"\"\n",
    "    Iarkho's features described in Iarkho's work on the evolution of 5-act tragedy in verse.\n",
    "    \"\"\"\n",
    "    metadata_dict['num_present_characters'] = number_present_characters(play_data)\n",
    "    metadata_dict['num_scenes_text'] = estimate_number_scenes(play_data['play_summary'])[0]\n",
    "    metadata_dict['num_scenes_iarkho'] = estimate_number_scenes(play_data['play_summary'])[1]\n",
    "    play_summary_copy = copy.deepcopy(play_data['play_summary'])\n",
    "    distribution, speech_types, non_speakers = speech_distribution_iarkho(play_summary_copy)\n",
    "    metadata_dict['speech_distribution'] = distribution\n",
    "    metadata_dict['percentage_monologues'] = speech_types['perc_monologue']\n",
    "    metadata_dict['percentage_duologues'] = speech_types['perc_duologue']\n",
    "    metadata_dict['percentage_non_duologues'] = speech_types['perc_non_duologue']\n",
    "    metadata_dict['percentage_above_two_speakers'] = speech_types['perc_over_two_speakers']\n",
    "    metadata_dict['av_percentage_non_speakers'] = non_speakers\n",
    "    metadata_dict['sigma_iarkho'] = round(sigma_iarkho(\n",
    "                                    [item[0] for item in metadata_dict['speech_distribution']],\n",
    "                                    [item[1] for item in metadata_dict['speech_distribution']]), 3)\n",
    "    \n",
    "    return metadata_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_of_scenes_discont_change(play_data, metadata_dict):\n",
    "    number_scenes = metadata_dict['num_scenes_iarkho']\n",
    "    characters = []\n",
    "    num_scenes_with_disc_character_change = 0\n",
    "    for act in play_data['play_summary'].keys():\n",
    "        for entry in play_data['play_summary'][act].values():\n",
    "            new_cast = [item for item in entry.keys() if \n",
    "                               item not in ['num_speakers', 'perc_non_speakers', 'num_utterances']]\n",
    "            if len(characters) > 0:\n",
    "                if len(set(new_cast).intersection(set(characters[-1]))) == 0:\n",
    "                    num_scenes_with_disc_character_change += 1\n",
    "            characters.append(new_cast)\n",
    "    perc_disc = round((num_scenes_with_disc_character_change /number_scenes) * 100, 3) \n",
    "    metadata_dict['number_scenes_with_discontinuous_change_characters'] = num_scenes_with_disc_character_change\n",
    "    metadata_dict['percentage_scenes_with_discontinuous_change_characters'] = perc_disc\n",
    "    \n",
    "    return metadata_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metadata_processing(play_string, play_data):\n",
    "    \"\"\"\n",
    "    Process all play features in stages\n",
    "    \"\"\"\n",
    "    metadata_dict = {}\n",
    "    for process in [process_speakers_features, percentage_of_scenes_discont_change]:\n",
    "        metadata_dict = process(play_data, metadata_dict)\n",
    "\n",
    "    return metadata_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_play_info(metadata):\n",
    "    \"\"\"\n",
    "    Update play metadata from the metadata_df.\n",
    "    \"\"\"\n",
    "    play_data = {}\n",
    "    play_data['title'] = metadata[0][0]\n",
    "    first_name = metadata[0][2]\n",
    "    if type(first_name) != float:\n",
    "        play_data['author'] = str(metadata[0][1] + ', ' + metadata[0][2]).replace('\\xa0', '')\n",
    "    else:\n",
    "        play_data['author'] = metadata[0][1].replace('\\xa0', '') \n",
    "    play_data['date'] = metadata[0][3]\n",
    "    \n",
    "    return play_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_play(file_name, metadata_df,  input_path):\n",
    "    \"\"\"\n",
    "    The function parses a txt file and creates a summary with features and metadata for the play.\n",
    "    Params:\n",
    "        file_name - a string, name of the file with the play text.\n",
    "        metadata_df - a dataframe containing the info about the play.\n",
    "    Returns:\n",
    "        play_data - a dictionary with detailed play summary by scenes, metadata, and features\n",
    "    \"\"\"\n",
    "    play_index = file_name.replace(input_path, '').replace('.docx', '').replace('F_', '')\n",
    "    play_meta = metadata_df[metadata_df['index']=='F_' + play_index][['title', 'last_name', \n",
    "                                                            'first_name', 'date']].values                                                      \n",
    "    comedy = docx2txt.process(file_name)\n",
    "    number_acts = int(metadata_df[metadata_df['index']=='F_'+play_index]['num_acts'].values[0])\n",
    "    play_data = add_play_info(play_meta)\n",
    "    play_data = process_play_summary(play_data, comedy)\n",
    "    play_data['metadata'] = metadata_processing(play_text, play_data)\n",
    "    \n",
    "    return play_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_plays(input_directory, output_path, metadata_path):\n",
    "    \"\"\"\n",
    "    The function allows to process all files in a specified directory.\n",
    "    Params:\n",
    "        input_directory - the path to the folder containing the txt files\n",
    "        output_path - directory in which the json summaries will be saved.\n",
    "        metadata_path - path to the metadata file, a tab-delimited txt file with informtion about all plays.\n",
    "        regex_pattern - a regex pattern which identifies dramatic character names.\n",
    "    Returns:\n",
    "        no returns, the files will be saved in output_path directory.\n",
    "    \"\"\"\n",
    "    all_files = [f for f in listdir(input_directory) if f.count('.docx')>0]\n",
    "    metadata_df = pd.read_csv(metadata_path, sep='\\t')\n",
    "    for file in all_files:\n",
    "        print(file)\n",
    "        play_data_dict = process_play(input_directory+file, metadata_df, input_directory)\n",
    "        json_name = output_path + 'F_' + str(file.replace('.docx', '.json')) \n",
    "        with open(json_name, 'w') as fp:\n",
    "            json.dump(play_data_dict, fp, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221.docx\n",
      "108.docx\n",
      "260.docx\n",
      "85.docx\n",
      "165.docx\n",
      "173.docx\n",
      "124.docx\n",
      "295.docx\n",
      "104.docx\n",
      "145.docx\n",
      "283.docx\n",
      "66.docx\n",
      "217.docx\n",
      "186.docx\n",
      "31.docx\n",
      "240.docx\n",
      "305.docx\n",
      "190.docx\n",
      "256.docx\n",
      "201.docx\n",
      "71.docx\n",
      "129.docx\n",
      "257.docx\n",
      "191.docx\n",
      "304.docx\n",
      "282.docx\n",
      "144.docx\n",
      "105.docx\n",
      "294.docx\n",
      "92.docx\n",
      "125.docx\n",
      "172.docx\n",
      "164.docx\n",
      "133.docx\n",
      "261.docx\n",
      "236.docx\n",
      "51.docx\n",
      "109.docx\n",
      "220.docx\n",
      "298.docx\n",
      "277.docx\n",
      "293.docx\n",
      "102.docx\n",
      "114.docx\n",
      "285.docx\n",
      "211.docx\n",
      "180.docx\n",
      "246.docx\n",
      "303.docx\n",
      "196.docx\n",
      "179.docx\n",
      "250.docx\n",
      "207.docx\n",
      "159.docx\n",
      "227.docx\n",
      "118.docx\n",
      "289.docx\n",
      "266.docx\n",
      "83.docx\n",
      "134.docx\n",
      "163.docx\n",
      "175.docx\n",
      "122.docx\n",
      "174.docx\n",
      "162.docx\n",
      "288.docx\n",
      "267.docx\n",
      "230.docx\n",
      "226.docx\n",
      "158.docx\n",
      "271.docx\n",
      "206.docx\n",
      "98.docx\n",
      "77.docx\n",
      "251.docx\n",
      "197.docx\n",
      "178.docx\n",
      "247.docx\n",
      "302.docx\n",
      "181.docx\n",
      "61.docx\n",
      "139.docx\n",
      "284.docx\n",
      "115.docx\n",
      "292.docx\n",
      "154.docx\n",
      "205.docx\n",
      "74.docx\n",
      "252.docx\n",
      "194.docx\n",
      "301.docx\n",
      "244.docx\n",
      "35.docx\n",
      "182.docx\n",
      "213.docx\n",
      "62.docx\n",
      "9.docx\n",
      "268.docx\n",
      "141.docx\n",
      "229.docx\n",
      "100.docx\n",
      "291.docx\n",
      "157.docx\n",
      "97.docx\n",
      "209.docx\n",
      "198.docx\n",
      "161.docx\n",
      "248.docx\n",
      "81.docx\n",
      "264.docx\n",
      "233.docx\n",
      "225.docx\n",
      "224.docx\n",
      "232.docx\n",
      "43.docx\n",
      "265.docx\n",
      "4.docx\n",
      "80.docx\n",
      "249.docx\n",
      "160.docx\n",
      "38.docx\n",
      "176.docx\n",
      "121.docx\n",
      "79.docx\n",
      "290.docx\n",
      "59.docx\n",
      "228.docx\n",
      "140.docx\n",
      "212.docx\n",
      "183.docx\n",
      "300.docx\n",
      "245.docx\n",
      "195.docx\n",
      "253.docx\n",
      "75.docx\n",
      "204.docx\n",
      "126.docx\n",
      "91.docx\n",
      "258.docx\n",
      "167.docx\n",
      "188.docx\n",
      "130.docx\n",
      "87.docx\n",
      "219.docx\n",
      "44.docx\n",
      "52.docx\n",
      "223.docx\n",
      "274.docx\n",
      "203.docx\n",
      "72.docx\n",
      "242.docx\n",
      "281.docx\n",
      "239.docx\n",
      "48.docx\n",
      "106.docx\n",
      "278.docx\n",
      "297.docx\n",
      "151.docx\n",
      "150.docx\n",
      "279.docx\n",
      "296.docx\n",
      "49.docx\n",
      "238.docx\n",
      "146.docx\n",
      "280.docx\n",
      "65.docx\n",
      "214.docx\n",
      "243.docx\n",
      "193.docx\n",
      "255.docx\n",
      "202.docx\n",
      "234.docx\n",
      "218.docx\n",
      "2.docx\n",
      "86.docx\n",
      "166.docx\n",
      "189.docx\n",
      "259.docx\n",
      "170.docx\n",
      "28.docx\n",
      "90.docx\n"
     ]
    }
   ],
   "source": [
    "process_all_plays('Word_Docs/', 'Play_Jsons/', 'French_Comedies.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "process_play('Word_Docs/104.docx', pd.read_csv('French_Comedies.tsv', sep='\\t'), 'Word_Docs/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "character_sets = []\n",
    "for act in play_data['play_summary'].keys():\n",
    "    for scene in play_data['play_summary'][act].keys():\n",
    "        new_character_set = set([key for key in play_data['play_summary'][act][scene].keys() \n",
    "               if key not in ['num_speakers', 'perc_non_speakers']])\n",
    "        character_sets.append(new_character_set)\n",
    "        if len(character_sets) > 1 and new_character_set == character_sets[-2] and scene.count('no_change')==0 and scene.count('1')==0:\n",
    "            print(act, scene, new_character_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
