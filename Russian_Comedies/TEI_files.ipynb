{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we process TEI files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os import path\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import string \n",
    "from bs4 import BeautifulSoup as bs\n",
    "import string\n",
    "import json\n",
    "import re\n",
    "import copy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_character_cast(play_soup):\n",
    "    dramatic_characters = play_soup.find_all('person')\n",
    "    character_dict = {}\n",
    "    for character_tag in dramatic_characters:\n",
    "        tag = str(character_tag)\n",
    "        xml_id = tag[tag.find('xml:id='):tag.find('>')].replace('\\\"', '').split('=')[-1]\n",
    "        # in case there is a collective number \n",
    "        collective_number = character_tag.find_all('collective_number')\n",
    "        if len(collective_number) != 0:\n",
    "            collect_number = int(collective_number[0].get_text())\n",
    "        else:\n",
    "            collect_number = None\n",
    "        character_dict[character_tag.find_all('persname')[0].get_text()] = {\"alternative_names\": xml_id,\n",
    "                                                                            \"collective_number\": collect_number}   \n",
    "    return character_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scene_status(scene):\n",
    "    scene_str = str(scene)\n",
    "    scene_desc = scene_str[scene_str.find('type='):scene_str.find('>')].replace('\\\"', '').split('=')[-1]\n",
    "    if scene_desc.count('extra') > 0:\n",
    "        scene_status = 'extra'\n",
    "    else:\n",
    "        scene_status = 'regular'\n",
    "        \n",
    "    return scene_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_scene_name_and_count(scene, sc_num, extra_scene_number):\n",
    "    \"\"\"\n",
    "    The function checks the scene status, whether it is extra or not and assigns the number. Extra scenes are counted\n",
    "    as for example 1.1 the first extra scene of the main scene 1.\n",
    "    Params:\n",
    "        scene - text of a scene.\n",
    "        sc_number - number of the scene as it appears in the order of all scenes for a particular act.\n",
    "        extra_scene_number - the number of the extra scene for each main scene, e.g. 1.1, 1.2, 1.3 etc. \n",
    "    Returns:\n",
    "        scene_status - whether a scene is regular, no_change, or extra.\n",
    "        sc_number - number of the main scene.\n",
    "        extra_scene_number - number of the extra scene.\n",
    "    \"\"\"\n",
    "    sc_num = int(float(sc_num))\n",
    "    scene_status = get_scene_status(scene)\n",
    "    if scene_status == 'extra':\n",
    "        sc_num = str(sc_num)+ '.'+str(extra_scene_number)\n",
    "        extra_scene_number+=1\n",
    "    else:\n",
    "        sc_num +=1\n",
    "        extra_scene_number = 1\n",
    "        \n",
    "    return scene_status, sc_num, extra_scene_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_utterance(scene):\n",
    "    utterance_dict = {}\n",
    "    utterances = scene.find_all('sp')\n",
    "    for utterance in utterances:\n",
    "        speaker_count = str(utterance).count('#')\n",
    "        if speaker_count > 1:\n",
    "            speaker_string = str(utterance)[str(utterance).find('#'):str(utterance).find('\\\">')]\n",
    "            speakers = speaker_string.split(' ')\n",
    "            for speaker in speakers:\n",
    "                utterance_dict[speaker] = speaker_string\n",
    "        \n",
    "    return utterance_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_word_name(character_cast_dict):\n",
    "    multi_word = []\n",
    "    for key in character_cast_dict.keys():\n",
    "        if key.count(' ') > 0:\n",
    "            multi_word.append(key)\n",
    "    if len(multi_word) > 0:\n",
    "        \n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tackle_name(character_cast_dict, scene_cast):\n",
    "    updated_characters = []\n",
    "    for name in character_cast_dict.keys():\n",
    "        if scene_cast.count(name.lower()) >= 2:\n",
    "            updated_characters.append(name)\n",
    "        elif scene_cast.count(name.lower()) == 1:\n",
    "            if name[-2:] != 'ин' and name[-2:] != 'ов' and name[-2:] != 'ев' and name[-2:] != 'аф':\n",
    "                updated_characters.append(name)\n",
    "            elif (scene_cast[scene_cast.find(name.lower()):scene_cast.find(name.lower())+len(name.lower())+1][-1] != 'а'and \n",
    "                 scene_cast[scene_cast.find(name.lower()):scene_cast.find(name.lower())+len(name.lower())+3][-1] != 'я'):\n",
    "                     updated_characters.append(name)\n",
    "    return updated_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_utterances(scene, character_cast_dict, previous_cast, scene_status):\n",
    "    scene_info = {}\n",
    "    if scene_status.count('extra') != 0 or str(scene).count('complex_scene') != 0:\n",
    "        scene_cast = str(scene)[str(scene).find('cast=\\\"'):str(scene).find('type')].lower()\n",
    "    else:\n",
    "        scene_cast = scene.find_all('stage')[0].get_text().lower()\n",
    "    if scene_cast.count('те же') > 0 or scene_cast.count('прежние') > 0 or scene_cast.count('те ж') > 0:\n",
    "        characters = previous_cast\n",
    "    else:\n",
    "        characters = []\n",
    "    updated_characters = tackle_name(character_cast_dict, scene_cast)\n",
    "    utterance_dictionary = check_utterance(scene)\n",
    "    # make sure to include previous cast in case some of the characters are the same\n",
    "    updated_characters = updated_characters + characters\n",
    "    if len(updated_characters) > 1:\n",
    "        for character in updated_characters:\n",
    "            in_scene = '#' + character_cast_dict[character]['alternative_names']\n",
    "            if len(utterance_dictionary) != 0 and in_scene in utterance_dictionary:\n",
    "                additional_utterances = len(scene.find_all('sp', {'who': utterance_dictionary[in_scene]}))\n",
    "            else:\n",
    "                additional_utterances = 0\n",
    "            num_utterances = additional_utterances + len(scene.find_all('sp', {'who': in_scene}))\n",
    "            scene_info[character] = num_utterances\n",
    "    else:\n",
    "        scene_info[updated_characters[0]] = 1\n",
    "        \n",
    "    return scene_info, characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_two_scenes(cast_one, cast_two):\n",
    "    \"\"\"\n",
    "    The function helps identify if the dramatic character cast changed.\n",
    "    Params:\n",
    "        cast_one - a list of characters in scene one.\n",
    "        cast_two - a list of characters in scene two.\n",
    "    Returns:\n",
    "        no_change_scene - 'no_change' if two scenes are the same, None otherwise.\n",
    "    \"\"\"\n",
    "    if set(cast_one) == set(cast_two):\n",
    "        no_change_scene = 'no_change'\n",
    "    else:\n",
    "        no_change_scene = None\n",
    "        \n",
    "    return no_change_scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_no_change(current_scene_cast, previous_cast, scene_status):\n",
    "    \"\"\"\n",
    "    The function checks if the cast for the new scene is different from the previous scene.\n",
    "    Params:\n",
    "        scene_names - a list of scenes names in the order they appear in the text.\n",
    "        scene_cast - a list of characters in the scene.\n",
    "        complete_scene_info - a dictionary where keys are scene_names and \n",
    "                                values are characters and their utterance counts.\n",
    "        scene_status - whether a scene is regular or extra.\n",
    "    Returns:\n",
    "        scene_status - a string, updated in case to 'no_change' if the character cast did not change.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # compare the current scene cast with the cast of the previous scene\n",
    "    no_change = compare_two_scenes(current_scene_cast, previous_cast)\n",
    "    if no_change:\n",
    "        scene_status = no_change   \n",
    "    \n",
    "    return scene_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_characters(scene_summary_dict):\n",
    "    \"\"\"\n",
    "    The function parses scene_summary_dict with information about number of utterances by each character\n",
    "    and identifies the total number of speakers and non_speakers.\n",
    "    Params:\n",
    "        scene_summary_dict: a dictionary where keys are dramatic characters and values are number of utterances.\n",
    "    Returns:\n",
    "        num_speakers - a number of speaking dramatic characters in the scene.\n",
    "        perc_non_speakers - percentage of non-speaking dramatic characters in the scene.\n",
    "    \"\"\"\n",
    "    summary = [item for item in scene_summary_dict.items() if item[0] != 'num_utterances' and item[0] != 'num_speakers']\n",
    "    num_speakers = len([item[0] for item in summary if item[1] != 0])\n",
    "    num_non_speakers = len([item[0] for item in summary if item[1] == 0]) \n",
    "    perc_non_speakers =  round((num_non_speakers / len(summary)) * 100, 3)\n",
    "    \n",
    "    return num_speakers, perc_non_speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_scenes(scenes, character_cast_dictionary):\n",
    "    \"\"\"\n",
    "    The function goes through a list of scenes and updates complete_scene_info dictionary with informtion\n",
    "    about each scene speaking characters, their utterance counts, and percentage of non-speaking characters.\n",
    "    Params:\n",
    "        scenes - a list scenes.\n",
    "        name_pattern - regex expression for identifying character names.\n",
    "        character_cast_dictionary, reverse_character_cast - dictionaries for lookup of alternative names \n",
    "                                                            for each dramatic character.\n",
    "    Returns:\n",
    "        complete_scene_info - a dictionary where keys are scenes and values are dramatic characters and their \n",
    "                             utternace counts as well as the number of speakers and percentage of non-speakers.\n",
    "    \"\"\"\n",
    "    other_meta_fields = ['num_speakers', 'perc_non_speakers', 'num_utterances']\n",
    "    complete_scene_info = {} \n",
    "    scene_names = []\n",
    "    sc_num = 0\n",
    "    extra_scene_number = 1\n",
    "    for scene in scenes:\n",
    "        scene_status, sc_num, extra_scene_number = handle_scene_name_and_count(scene, sc_num, extra_scene_number)\n",
    "        if sc_num != 1 :\n",
    "            previous_cast = [name for name in complete_scene_info[scene_names[-1]].keys()\n",
    "                            if name not in other_meta_fields]\n",
    "        else:\n",
    "            previous_cast = []\n",
    "        scene_summary, scene_cast = count_utterances(scene, character_cast_dictionary, previous_cast, scene_status)\n",
    "        scene_summary['num_utterances'] = sum(list(scene_summary.values()))\n",
    "        scene_summary['num_speakers'], scene_summary['perc_non_speakers'] = count_characters(scene_summary)\n",
    "        if float(sc_num) > 1:\n",
    "            current_scene = [key for key in scene_summary.keys() if key not in other_meta_fields]\n",
    "            scene_status = check_if_no_change(current_scene, previous_cast, scene_status)           \n",
    "        complete_scene_info[str(sc_num) + '_' + str(scene_status)] =  scene_summary\n",
    "        #check to make sure all character names are in scene cast as they appear in the play cast\n",
    "        scene_names.append(str(sc_num) + '_' + str(scene_status))\n",
    "\n",
    "    return complete_scene_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_summary(soup, character_cast_dictionary):  \n",
    "    act_info = {}\n",
    "    acts = soup.find_all('div', {'type': 'act'})\n",
    "    for act_num, act in enumerate(acts, 1):\n",
    "        scenes = act.find_all('div', {'type': ['scene', 'extra_scene', 'complex_scene']})\n",
    "        act_info['act'+'_'+str(act_num)] = parse_scenes(scenes, \n",
    "                                                        character_cast_dictionary)\n",
    "    return act_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_present_characters(play_dictionary):\n",
    "    \"\"\"\n",
    "    The function calculates the number of characters present in the play. If a character is listed in cast, but doesn't\n",
    "    appear on stage, he/she doesn't count.\n",
    "    Params:\n",
    "        play_dictionary - a dictioanry with data for the play, which includes the characters present in each scene.\n",
    "    Returns:\n",
    "        total_number_present_characters - int.\n",
    "    \"\"\"\n",
    "    all_present_characters = set()\n",
    "    for key in play_dictionary['play_summary'].keys():\n",
    "        for scene in play_dictionary['play_summary'][key]:\n",
    "            for item in play_dictionary['play_summary'][key][scene].keys():\n",
    "                if item != 'num_utterances' and item != 'num_speakers' and item != 'perc_non_speakers':\n",
    "                    all_present_characters.add(item)\n",
    "    total_number_present_characters = 0\n",
    "    appearing_on_stage = set(play_dictionary['characters']).intersection(all_present_characters)\n",
    "    for character in appearing_on_stage: \n",
    "        coll_number = play_dictionary['characters'][character]['collective_number']\n",
    "        # if there is a collective number for this character\n",
    "        if coll_number:\n",
    "            total_number_present_characters += int(coll_number)\n",
    "        else:\n",
    "            total_number_present_characters += 1\n",
    "\n",
    "    return total_number_present_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_number_scenes(scene_summary):\n",
    "    \"\"\"\n",
    "    The function calcualtes the number of scenes per text and per Iarkho (i.e., as marked by actual dramatic character\n",
    "    entrances and exits).\n",
    "    Params:\n",
    "        scene_summary - a dictionary output of the parse_play function.\n",
    "    Returns:\n",
    "        total_number_scenes_per_text - number of scenes as they are printed\n",
    "        total_number_scenes_iarkho - number of scnes per Iarkho, which he calls mobility coefficient (MC)\n",
    "    \"\"\"\n",
    "    total_number_scenes_per_text = 0\n",
    "    total_number_scenes_iarkho = 0\n",
    "    for key in scene_summary.keys():\n",
    "        # get the number of scenes as it is printed in the text\n",
    "        total_number_scenes_per_text+=len([scene for scene in scene_summary[key].keys() if scene.count('extra')==0])\n",
    "        # count scenes as marked by actual entrances and exits                                  \n",
    "        total_number_scenes_iarkho+=len([scene for scene in scene_summary[key].keys() if scene.count('no_change')==0])\n",
    "    \n",
    "    return total_number_scenes_per_text, total_number_scenes_iarkho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_speaking_no_change_case(previous_scene, no_change_scene):\n",
    "    speaking_set = set()\n",
    "    non_speaking_set = set()\n",
    "    characters = [key for key in previous_scene.keys() if key not in [\"num_utterances\", \n",
    "                                                         \"num_speakers\", \n",
    "                                                         \"perc_non_speakers\"]]\n",
    "    for key in characters:\n",
    "        if previous_scene[key] > 0 or no_change_scene[key] > 0:\n",
    "            speaking_set.add(key)\n",
    "        if previous_scene[key] == 0 or no_change_scene[key]== 0:\n",
    "            non_speaking_set.add(key)\n",
    "    num_non_speaking = len(non_speaking_set.difference(speaking_set))\n",
    "    num_speaking = len(speaking_set)\n",
    "    perc_non_speaking = round((num_non_speaking / (num_non_speaking + num_speaking)) * 100, 3)\n",
    "    \n",
    "    return num_speaking, perc_non_speaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_no_change_scenes(play_summary):\n",
    "    which_to_exclude = []\n",
    "    speakers = []\n",
    "    perc_non_speakers = []\n",
    "    for act in play_summary.keys():\n",
    "        analysed_scenes = []\n",
    "        for scene in list(play_summary[act].keys()):\n",
    "            if scene.count('no_change') > 0:\n",
    "\n",
    "                num_speaking, perc_non_speaking = number_speaking_no_change_case(\n",
    "                                                  play_summary[act][analysed_scenes[-1]],\n",
    "                                                  play_summary[act][scene])\n",
    "                speakers.append(num_speaking)\n",
    "                perc_non_speakers.append(perc_non_speaking)\n",
    "                which_to_exclude.append((act, scene, analysed_scenes[-1]))\n",
    "            analysed_scenes.append(scene)\n",
    "    \n",
    "    return which_to_exclude, speakers, perc_non_speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_combined_scenes(play_dict, values_to_exclude):\n",
    "    \"\"\"\n",
    "    The function removes info about scenes that we have previously combined and calculated combined data\n",
    "    for in cases when there was no change in character cast.\n",
    "    Params:\n",
    "        play_dict - a dictionary with speakers for each scene.\n",
    "        values_to_exlude - a list of typles where the first value is the act and the other values are scenes.\n",
    "        \n",
    "    Returns:\n",
    "        play_dict - without exluded scenes.\n",
    "    \"\"\"\n",
    "    for value in values_to_exclude:\n",
    "        result = {key : val for key, val in play_dict[value[0]].items() \n",
    "                        if key not in value[1:]}\n",
    "        play_dict[value[0]] = result\n",
    "        \n",
    "    return play_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_play_summary(play_summary_copy):\n",
    "    values_to_exclude, speakers, perc_non_speakers = combine_no_change_scenes(play_summary_copy)\n",
    "    play_summary_updated = remove_combined_scenes(play_summary_copy, values_to_exclude)\n",
    "    for key in play_summary_updated.keys():\n",
    "        for scene in play_summary_updated[key]:\n",
    "            speakers.append((play_summary_updated[key][scene]['num_speakers']))\n",
    "            perc_non_speakers.append(round(play_summary_updated[key][scene]['perc_non_speakers'], 3))\n",
    "    \n",
    "    return speakers, perc_non_speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_distribution_iarkho(play_summary_copy):\n",
    "    \"\"\"\n",
    "    The function creates speech distrubution per Iarkho, i.e., the number of speaking characters by number of scenes.\n",
    "    Params:\n",
    "        play_summary - a dictionary output by parse_play function.\n",
    "    Returns:\n",
    "        speech_distribution - a list of tuples were the 0 element is the number of speaking characters\n",
    "                              and the 1 element is the number of scenes with such number of speaking characters.\n",
    "    \"\"\"\n",
    "    \n",
    "    speakers, perc_non_speakers = preprocess_play_summary(play_summary_copy)\n",
    "    counter = Counter\n",
    "    counted = counter(speakers)\n",
    "    speech_distribution = sorted(counted.items(), key=lambda pair: pair[0], reverse=False)\n",
    "    speech_types = percentage_of_each_speech_type(speech_distribution)\n",
    "    av_perc_non_speakers = round(np.mean((perc_non_speakers)), 3)\n",
    "    \n",
    "    return speech_distribution, speech_types, av_perc_non_speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma_iarkho(variants, weights):  \n",
    "    \"\"\" \n",
    "    The function allows calculating standard range following iarkho's procedure. \n",
    "    Parameters: \n",
    "        variants - a list with distinct variants in the ascending order, e.g. [1, 2, 3, 4, 5] \n",
    "        weights - a list of weights corresponding to these variants, e.g. [20, 32, 18, 9, 1] \n",
    "    Returns: \n",
    "        sigma - standard range per iarkho \n",
    "    \"\"\"  \n",
    "    weighted_mean_variants = np.average(variants, weights=weights)  \n",
    "    differences_squared = [(variant - weighted_mean_variants)**2 for variant in variants] \n",
    "    weighted_mean_difference = np.average(differences_squared, weights=weights)  \n",
    "    sigma = weighted_mean_difference**0.5  \n",
    "      \n",
    "    return sigma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_speakers_features(soup, play_data, metadata_dict):\n",
    "    \"\"\"\n",
    "    Iarkho's features described in Iarkho's work on the evolution of 5-act tragedy in verse.\n",
    "    \"\"\"\n",
    "    metadata_dict['num_present_characters'] = number_present_characters(play_data)\n",
    "    metadata_dict['num_scenes_text'] = estimate_number_scenes(play_data['play_summary'])[0]\n",
    "    metadata_dict['num_scenes_iarkho'] = estimate_number_scenes(play_data['play_summary'])[1]\n",
    "    play_summary_copy = copy.deepcopy(play_data['play_summary'])\n",
    "    distribution, speech_types, non_speakers = speech_distribution_iarkho(play_summary_copy)\n",
    "    metadata_dict['speech_distribution'] = distribution\n",
    "    metadata_dict['percentage_monologues'] = speech_types['perc_monologue']\n",
    "    metadata_dict['percentage_duologues'] = speech_types['perc_duologue']\n",
    "    metadata_dict['percentage_non_duologues'] = speech_types['perc_non_duologue']\n",
    "    metadata_dict['percentage_above_two_speakers'] = speech_types['perc_over_two_speakers']\n",
    "    metadata_dict['av_percentage_non_speakers'] = non_speakers\n",
    "    metadata_dict['sigma_iarkho'] = round(sigma_iarkho(\n",
    "                                    [item[0] for item in metadata_dict['speech_distribution']],\n",
    "                                    [item[1] for item in metadata_dict['speech_distribution']]), 3)\n",
    "    \n",
    "    return metadata_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_of_each_speech_type(speech_distribution):\n",
    "    \"\"\"\n",
    "    The function calculates the percentage of each speech type (monologue, duologue, non-duologue (meaning not two\n",
    "    speakers), and over-two speakers) of the total accross all speech types.\n",
    "    Params:\n",
    "        speech_distibution - number of scenes with a specified number of speakers.\n",
    "    Returns:\n",
    "        speech_types - a dictionary with percentages corresponding to each speech type.\n",
    "    \"\"\"\n",
    "    speech_types = {}\n",
    "    total_scenes = np.sum([speech_type[1] for speech_type in  speech_distribution])\n",
    "    speech_types['perc_monologue'] = np.round((np.sum([speech_type[1] for speech_type in  speech_distribution \n",
    "                                    if speech_type[0] ==1]) / total_scenes) *100, 2)\n",
    "    speech_types['perc_duologue'] = np.round((np.sum([speech_type[1] for speech_type in  speech_distribution \n",
    "                                    if speech_type[0] == 2])/ total_scenes) * 100, 2)\n",
    "    speech_types['perc_non_duologue'] = np.round((np.sum([speech_type[1] for speech_type in  speech_distribution \n",
    "                                        if speech_type[0] != 2])/ total_scenes) * 100, 2)\n",
    "    speech_types['perc_over_two_speakers'] = np.round((np.sum([speech_type[1] for speech_type in  speech_distribution \n",
    "                                             if speech_type[0] > 2])/ total_scenes) * 100, 2)\n",
    "    \n",
    "    return speech_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_utterances(play_soup):\n",
    "    \"\"\"\n",
    "    The function parses the dictionary with play_summary produced by parse_play function\n",
    "    and outputs total number of utterances \n",
    "    Params:\n",
    "        play_summary - a dictionary output by parse_play function.\n",
    "        \n",
    "    Returns:\n",
    "        total_utterances_in_play - total number of utterances in a play.\n",
    "    \"\"\"\n",
    "    total_utterances_in_play = len(play_soup.find_all('sp'))       \n",
    "    \n",
    "    return total_utterances_in_play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_all_verse_lines(soup):\n",
    "    all_lines = soup.find_all('l')\n",
    "    not_init = soup.find_all('l', {\"part\": \"M\"}) + soup.find_all('l', {\"part\": \"F\"})\n",
    "    num_verse_lines = len([line for line in all_lines if line not in not_init])\n",
    "    \n",
    "    return num_verse_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verse_split_between_scenes(soup):\n",
    "    scenes = soup.find_all('div', {'type': ['scene', 'extra_scene', 'complex_scene']})\n",
    "    counts = {'scenes_with_split_verse':0, 'scenes_split_rhymes':0, 'both':0, 'open': 0}\n",
    "    for scene in scenes:\n",
    "        last_ten_lines = str(scene.find_all('l')[-10:])\n",
    "        last_line = str(scene.find_all('l')[-1])\n",
    "        verse = last_line[last_line.find(\"\\\"\"):last_line.find('>')].replace('\\\"', '').split(' ')[0]\n",
    "        if verse.count('M') > 0 or verse.count('I') > 0:\n",
    "            counts['scenes_with_split_verse'] += 1\n",
    "        if last_ten_lines.count('interscene') > 0:\n",
    "            counts['scenes_split_rhymes'] += 1\n",
    "        if (verse.count('M') > 0 or verse.count('I') > 0) and last_ten_lines.count('interscene') > 0:\n",
    "            counts['both'] += 1\n",
    "        if verse.count('M') > 0 or verse.count('I') > 0 or last_ten_lines.count('interscene') > 0:\n",
    "            counts['open'] += 1\n",
    "            \n",
    "    counts['percentage_scene_split_verse'] = round((counts['scenes_with_split_verse'] / len(scenes)) * 100, 3)\n",
    "    counts['percentage_scene_rhymes'] = round((counts['scenes_split_rhymes'] / len(scenes)) * 100, 3)\n",
    "    counts['percentage_scenes_rhymes_split_verse'] = round((counts['both'] / len(scenes)) * 100, 3)\n",
    "    counts['percentage_open_scenes'] = round((counts['open'] / len(scenes)) * 100, 3)\n",
    "    \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_features_verse(play_soup, play_data, metadata_dict):\n",
    "    \"\"\"\n",
    "    Iarkho's features described in the work on Corneille's comedies and tragedies.\n",
    "    \"\"\"\n",
    "    metadata_dict['total_utterances'] = total_utterances(play_soup)\n",
    "    metadata_dict['num_verse_lines'] = count_all_verse_lines(play_soup)\n",
    "    if play_data['free_iambs'] == 1:\n",
    "        metadata_dict['rescaled_num_verse_lines'] = round(metadata_dict['num_verse_lines'] * .796, 3)\n",
    "        metadata_dict['dialogue_vivacity'] = round(\n",
    "                                         metadata_dict['total_utterances'] / \n",
    "                                         metadata_dict['rescaled_num_verse_lines'], 3)\n",
    "    else:\n",
    "        metadata_dict['dialogue_vivacity'] = round(\n",
    "                                             metadata_dict['total_utterances'] / \n",
    "                                             metadata_dict['num_verse_lines'], 3)\n",
    "    metadata_dict['num_scenes_with_split_verse_lines'] = verse_split_between_scenes(\n",
    "                                                         play_soup)['scenes_with_split_verse']\n",
    "    metadata_dict['num_scenes_with_split_rhymes'] = verse_split_between_scenes(\n",
    "                                                    play_soup)['scenes_split_rhymes']\n",
    "    metadata_dict['percentage_scene_split_verse'] = verse_split_between_scenes(\n",
    "                                                    play_soup)['percentage_scene_split_verse']\n",
    "    metadata_dict['percentage_scene_split_rhymes'] = verse_split_between_scenes(\n",
    "                                                    play_soup)['percentage_scene_rhymes']\n",
    "    metadata_dict['num_scenes_with_split_rhymes_verses'] = verse_split_between_scenes(\n",
    "                                                           play_soup)['both']\n",
    "    metadata_dict['num_open_scenes'] = verse_split_between_scenes(\n",
    "                                       play_soup)['open']\n",
    "    metadata_dict['percentage_open_scenes'] = verse_split_between_scenes(\n",
    "                                              play_soup)['percentage_open_scenes']\n",
    "    metadata_dict['percentage_scenes_rhymes_split_verse'] = verse_split_between_scenes(\n",
    "                                                            play_soup)['percentage_scenes_rhymes_split_verse']\n",
    "    \n",
    "    return metadata_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitting_verse_line(scene):\n",
    "    splits= re.split('<l>|<l part=\"I\">', scene)\n",
    "    \n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_verse_line_splitting_stage_directions(play_soup):\n",
    "    splits = splitting_verse_line(str(play_soup))\n",
    "    total_num = 0\n",
    "    for line in splits[1:]:\n",
    "        # find the index of the end of the verse line\n",
    "        end = [i for i in re.finditer(r'</l>', line)][-1].span()[0]\n",
    "        verse_line = line[:end]\n",
    "        if verse_line.count('</stage>')> 0:\n",
    "            total_num+=verse_line.count('</stage>')\n",
    "            \n",
    "    return total_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_number_word_tokens(play_soup):\n",
    "    stage_directions = play_soup.find_all('stage')\n",
    "    total_number_tokens = 0\n",
    "    for sd in stage_directions:\n",
    "        sd = sd.get_text()\n",
    "        for punct in string.punctuation+'stage'+'\\n':\n",
    "            sd = sd.replace(punct, '')\n",
    "        total_number_tokens += len(sd.split())\n",
    "\n",
    "    return total_number_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_stage_directions_features(play_soup, play_data, metadata_dict):\n",
    "    \"\"\"\n",
    "    Sperantov's stage-directions features\n",
    "    \"\"\"\n",
    "    if play_data['free_iambs'] == 1:\n",
    "        number_verse_lines = metadata_dict['rescaled_num_verse_lines']\n",
    "    else:\n",
    "        number_verse_lines = metadata_dict['num_verse_lines']\n",
    "    metadata_dict['num_stage_directions'] = len(play_soup.find_all('stage'))\n",
    "    metadata_dict['stage_directions_frequency'] = round((metadata_dict['num_stage_directions'] /\n",
    "                                                  number_verse_lines) * 100, 3)\n",
    "    metadata_dict['num_word_tokens_in_stage_directions'] = count_number_word_tokens(play_soup)\n",
    "    metadata_dict['average_length_of_stage_direction'] = round(metadata_dict['num_word_tokens_in_stage_directions']/\n",
    "                                                        metadata_dict['num_stage_directions'], 3)\n",
    "    metadata_dict['num_verse_splitting_stage_directions'] = estimate_verse_line_splitting_stage_directions(play_soup)\n",
    "    \n",
    "    metadata_dict['degree_of_verse_prose_interaction'] = round((metadata_dict['num_verse_splitting_stage_directions'] /\n",
    "                                                             number_verse_lines) * 100, 3)\n",
    "    \n",
    "    return metadata_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_play_info(metadata, custom_flag=False):\n",
    "    \"\"\"\n",
    "    Update play metadata from the metadata_df. We can provide our own metadata or use the TEI metadataa\n",
    "    \"\"\"\n",
    "    play_data = {}\n",
    "    if custom_flag:\n",
    "        play_data['title'] = metadata[0][0]\n",
    "        play_data['author'] = metadata[0][1] + ', ' + metadata[0][2]\n",
    "        play_data['creation_date'] = metadata[0][3]\n",
    "        play_data['free_iambs'] = metadata[0][4]\n",
    "    else:\n",
    "        play_data['title'] = soup.find_all('title', {'type':'main'})[0].get_text()\n",
    "        play_data['author'] = soup.find_all('author')[0].get_text()\n",
    "        play_data['creation_date'] = int(soup.find_all('date', \n",
    "                                     {'type':'written'})[0].get_text().split()[0].replace('\\\"', ''))\n",
    "        \n",
    "    return play_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_of_scenes_discont_change(play_soup, play_data, metadata_dict):\n",
    "    number_scenes = metadata_dict['num_scenes_iarkho']\n",
    "    characters = []\n",
    "    num_scenes_with_disc_character_change = 0\n",
    "    for act in play_data['play_summary'].keys():\n",
    "        for entry in play_data['play_summary'][act].values():\n",
    "            new_cast = [item for item in entry.keys() if \n",
    "                               item not in ['num_speakers', 'perc_non_speakers', 'num_utterances']]\n",
    "            if len(characters) > 0:\n",
    "                if len(set(new_cast).intersection(set(characters[-1]))) == 0:\n",
    "                    num_scenes_with_disc_character_change += 1\n",
    "            characters.append(new_cast)\n",
    "    perc_disc = round((num_scenes_with_disc_character_change /number_scenes) * 100, 3) \n",
    "    metadata_dict['number_scenes_with_discontinuous_change_characters'] = num_scenes_with_disc_character_change\n",
    "    metadata_dict['percentage_scenes_with_discontinuous_change_characters'] = perc_disc\n",
    "    \n",
    "    return metadata_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def additional_metadata(play_soup, play_data):\n",
    "    \"\"\"\n",
    "    Process all play features in stages\n",
    "    \"\"\"\n",
    "    metadata_dict = {}\n",
    "    for process in [process_speakers_features, process_features_verse, \n",
    "                   process_stage_directions_features, percentage_of_scenes_discont_change]:\n",
    "        metadata_dict = process(play_soup, play_data, metadata_dict)\n",
    "\n",
    "    return metadata_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_play(file_name, metadata_df, custom_flag):\n",
    "    \"\"\"\n",
    "    The function parses a txt file and creates a summary with features and metadata for the play.\n",
    "    Params:\n",
    "        file_name - a string, name of the file with the play text.\n",
    "        metadata_df - a dataframe containing the info about the play.\n",
    "    Returns:\n",
    "        play_data - a dictionary with detailed play summary by scenes, metadata, and features\n",
    "    \"\"\"\n",
    "    print(file_name)\n",
    "    with open(file_name, 'r') as file:\n",
    "        soup = bs(file, 'lxml')\n",
    "    if custom_flag:\n",
    "        play_index = file_name.replace('TEI_files/', '').replace('.xml', '')\n",
    "        play_meta = metadata_df[metadata_df['index']==play_index][['title', 'last_name', \n",
    "                                                               'first_name', 'creation_date', \n",
    "                                                                'free_iambs']].values \n",
    "        comedy = open(file_name, 'r') .read()\n",
    "        number_acts = int(metadata_df[metadata_df['index']==play_index]['num_acts'].values[0])\n",
    "    else:\n",
    "        play_meta = []\n",
    "    play_data = add_play_info(play_meta, custom_flag)\n",
    "    play_data['characters'] = create_character_cast(soup)\n",
    "    play_data['play_summary'] = process_summary(soup, play_data['characters'])\n",
    "    play_data['metadata'] = additional_metadata(soup, play_data)\n",
    "    \n",
    "    return play_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_plays(input_directory, output_path, custom_flag=False, metadata_path=None):\n",
    "    \"\"\"\n",
    "    The function allows to process all files in a specified directory.\n",
    "    Params:\n",
    "        input_directory - the path to the folder containing the txt files\n",
    "        output_path - directory in which the json summaries will be saved.\n",
    "        metadata_path - path to the metadata file, a tab-delimited txt file with informtion about all plays.\n",
    "    Returns:\n",
    "        no returns, the files will be saved in output_path directory.\n",
    "    \"\"\"\n",
    "    all_files = [f for f in listdir(input_directory) if f.count('.xml')>0]\n",
    "    if custom_flag:\n",
    "        metadata_df = pd.read_csv(metadata_path, sep='\\t')\n",
    "    else:\n",
    "        metadata_df = pd.DataFrame()\n",
    "    for file in all_files:\n",
    "        play_data_dict = process_play(input_directory+file, metadata_df, custom_flag)\n",
    "        json_name = output_path +str(file.replace('.xml', '.json')) \n",
    "        with open(json_name, 'w') as fp:\n",
    "            json.dump(play_data_dict, fp, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEI_files/R_22.xml\n",
      "TEI_files/R_18.xml\n",
      "TEI_files/R_16.xml\n",
      "TEI_files/R_17.xml\n",
      "TEI_files/R_13.xml\n",
      "TEI_files/R_10.xml\n",
      "TEI_files/R_6.xml\n",
      "TEI_files/R_1.xml\n",
      "TEI_files/R_3.xml\n",
      "TEI_files/R_2.xml\n"
     ]
    }
   ],
   "source": [
    "process_all_plays('TEI_files/', 'Play_Jsons/', True, 'Russian_Comedies.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "process_play('TEI_files/R_6.xml', pd.read_csv('Russian_Comedies.tsv', sep='\\t'), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
